<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Matteo Risso - Weekly Summary</title>
    <subtitle>Well, Hi</subtitle>
    <link rel="self" type="application/atom+xml" href="https://matteorisso.github.io/tags/weekly-summary/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://matteorisso.github.io/"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2024-08-12T00:00:00+00:00</updated>
    <id>https://matteorisso.github.io/tags/weekly-summary/atom.xml</id>
    <entry xml:lang="en">
        <title>Weekly Summary 02</title>
        <published>2024-08-12T00:00:00+00:00</published>
        <updated>2024-08-12T00:00:00+00:00</updated>
        
        <author>
          <name>
            Matteo Risso
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://matteorisso.github.io/blog/ws02/"/>
        <id>https://matteorisso.github.io/blog/ws02/</id>
        
        <content type="html" xml:base="https://matteorisso.github.io/blog/ws02/">&lt;h1 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;&#x2F;h1&gt;
&lt;p&gt;Last time after some blabbering I put a picture of my cat, so I think that I will do the same this time.&lt;&#x2F;p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;matteorisso.github.io&#x2F;blog&#x2F;ws02&#x2F;ef.jpg&quot; alt=&quot;ef&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;figcaption&gt;Elio Fabrizio, again.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;
&lt;p&gt;Anyway, this week I have mainly (only) readings to share.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;readings&quot;&gt;Readings&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;We are going on with &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;G%C3%B6del,_Escher,_Bach&quot;&gt;&lt;em&gt;G√∂del, Escher, Bach: an Eternal Golden Braid&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; by Douglas Hofstadter. The story about Babbage and LAdy Lovelace is really interesting. I didn‚Äôt know about these two computing pioneers. Btw, now that I think about it Lovelace is the name for the microarchitecture of the Nvidia RTX 4090 GPU, the successor of Ampere. I hope that the next one will be called Babbage. Anyway, me and my girlfriend enjoyed a lot playing with the MIU formal system. We both agree that is not possible to go from MI to MU.&lt;&#x2F;li&gt;
&lt;li&gt;I started reading &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Identity_(novel)&quot;&gt;&lt;em&gt;Identity&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; by Milan Kundera. I want to read something that is not science-related to relax a bit. I chose this book because during the high-school I read &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Joke_(novel)&quot;&gt;&lt;em&gt;The Joke&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; by the same author and I really liked it. I‚Äôm about at 25% of the book and I should say that Kundera is reaaaaally good at writing, even if I don‚Äôt care about the story itself.&lt;&#x2F;li&gt;
&lt;li&gt;I listened to the first two lectures of the YouTube course &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;playlist?list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_&quot;&gt;&lt;em&gt;Category Theory&lt;&#x2F;em&gt;&lt;&#x2F;a&gt; by Bartosz Milewski. Honestly, I only listened to it passively while doing home chores, I definetely need to rewatch them with a notebook in my hand. I‚Äôm so fascinated by this abstract stuff and discovering that there are connections between category theory and computer science intrigued me a lot. I hope to understand something more in the next weeks. Btw, Bartosz is so similar to Frank Zappa, lol.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;matteorisso.github.io&#x2F;blog&#x2F;ws02&#x2F;meme.png&quot; alt=&quot;meme&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;figure&gt;
&lt;ul&gt;
&lt;li&gt;I subscribed to mathstodon. Here it is my &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;mathstodon.xyz&#x2F;@mattrix96&quot;&gt;profile&lt;&#x2F;a&gt;. This the second time that I try this platform, but honestly, I don‚Äôt like it. I think that I will stick with Twitter for now.&lt;&#x2F;li&gt;
&lt;li&gt;Victor (more or less) open-sourced the program discovery stuff that he is cooking. Everyday I think that this stuff could be huge in the EDA field. Apparently, he will at some point release API to use this stuff. I‚Äôm really curious about it. It is possible to read more in this &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;gist.github.com&#x2F;VictorTaelin&#x2F;7fe49a99ebca42e5721aa1a3bb32e278&quot;&gt;gist&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github-roast.pages.dev&quot;&gt;GitHub Profile Roast üî•üî•üî•&lt;&#x2F;a&gt;. Self-explanatory. Very funny.&lt;&#x2F;li&gt;
&lt;li&gt;I discovered the &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;nvcc4jupyter.readthedocs.io&#x2F;en&#x2F;latest&#x2F;usage.html&quot;&gt;nvcc4jupyter&lt;&#x2F;a&gt; package. This package allow to use Colab GPUs to run generic CUDA code. My plan is to study Bend examples and then try them with such GPUs. I already checked an free GPUs are T4s and it is stated that HVM should work with GPUs with at least &lt;strong&gt;right now I‚Äôm not able to find this number&lt;&#x2F;strong&gt;. T4 GPUs &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;tesla-t4.c3316&quot;&gt;should have&lt;&#x2F;a&gt; smaller L1 memory (i.e., 64kB), I want to see if this could be a problem for Bend. Instead, the &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;images.nvidia.com&#x2F;aem-dam&#x2F;en-zz&#x2F;Solutions&#x2F;design-visualization&#x2F;technologies&#x2F;turing-architecture&#x2F;NVIDIA-Turing-Architecture-Whitepaper.pdf&quot;&gt;technical document&lt;&#x2F;a&gt; for the Turing architecture states that such number is 96kB. It would be really cool to understand how to fix stuff in the case it does not work. Anyway, I think it would be really nice to have a way to test HVM-CUDA on free GPUs. Another source of free GPUs is kaggle, but I don‚Äôt know if it is possible to use them for this purpose.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.vortexa.com&#x2F;product-blog&#x2F;using-rust-to-corrode-insane-python-run-times&#x2F;&quot;&gt;Corrode Python&lt;&#x2F;a&gt;. This blogpost describes how to use Rust to speed up portions of Python code. Really interesting pointer.&lt;&#x2F;li&gt;
&lt;li&gt;I found &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;public.work&quot;&gt;this&lt;&#x2F;a&gt; really nice search-engine for copyrright-free images. I love them.&lt;&#x2F;li&gt;
&lt;li&gt;It seems that a first experimental python version without GIL is available. Nice. Read more [here](- &lt;&#x2F;li&gt;
&lt;li&gt;https:&#x2F;&#x2F;geekpython.in&#x2F;gil-become-optional-in-python).&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;kevinlynagh.com&#x2F;z3-simpsons-paradox&#x2F;&quot;&gt;Z3 theorem prover with an example&lt;&#x2F;a&gt;. I‚Äôm really intrigued by understanding how this stuff works. You give some constraint and then it enumaretes stuff to find an example that match constraints?&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;python-graph-gallery.com&#x2F;color-palette-finder&#x2F;&quot;&gt;Nice color palettes for Python plots&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zCcAg-vcpys&amp;amp;t=1264s&quot;&gt;This&lt;&#x2F;a&gt; is a livestream by Wolfram Alpha guys speaking and showing some code (in Mathematica) about interaction combinators. I‚Äôm happy to see that something is moving in this niece field.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Weekly Summary 01</title>
        <published>2024-08-05T00:00:00+00:00</published>
        <updated>2024-08-05T00:00:00+00:00</updated>
        
        <author>
          <name>
            Matteo Risso
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://matteorisso.github.io/blog/ws01/"/>
        <id>https://matteorisso.github.io/blog/ws01/</id>
        
        <content type="html" xml:base="https://matteorisso.github.io/blog/ws01/">&lt;h1 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;&#x2F;h1&gt;
&lt;p&gt;This is my first post tagged as &lt;strong&gt;Weekly Summary&lt;&#x2F;strong&gt;. 
Honestly, I started this ‚Äúproject‚Äù mainly because I would like to follow the ‚Äúlearning in public‚Äù philosophy.
Writing down every day something is definitely to much for someone like me who doesn‚Äôt like to write, but I think that a weekly summary is a good compromise.
By the way, this is public but I don‚Äôt know if someone will ever read this. Anyway, I don‚Äôt care.&lt;&#x2F;p&gt;
&lt;p&gt;Every section will deal with something that I read, studied or worked on during the week.&lt;&#x2F;p&gt;
&lt;p&gt;Here it is a picture of my cat, because, why not!&lt;&#x2F;p&gt;
&lt;figure&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;matteorisso.github.io&#x2F;blog&#x2F;ws01&#x2F;ef.jpg&quot; alt=&quot;ef&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;figcaption&gt;Elio Fabrizio, the cat of mine and my girlfriend.&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;
&lt;h1 id=&quot;backpropagation-algorithm&quot;&gt;Backpropagation Algorithm&lt;&#x2F;h1&gt;
&lt;p&gt;As a Deep Learning practitioner for about 3 years, I should say &lt;strong&gt;yes&lt;&#x2F;strong&gt;, I know really well how to compute derivatives and how to apply the backpropagation algorithm.
Honestly, PyTorch is such a niece piece of code, that yes, I know how stuff works in principle, but last time I computed a derivative by hand was probably during Calculus.
Shame on me, I know.&lt;&#x2F;p&gt;
&lt;p&gt;For a research project that I‚Äôm working on, I need to deep dive into this so I started to read some nice resources about the topic.&lt;&#x2F;p&gt;
&lt;p&gt;I will briefly list them here.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;derivatives-backpropagation-and-vectorization&quot;&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;cs231n.stanford.edu&#x2F;handouts&#x2F;derivatives.pdf&quot;&gt;Derivatives, Backpropagation, and Vectorization&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;em&gt;by Justin Johnson, Stanford University.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This is are really nice LaTex notes that first explain derivatives starting from the scalar case, moving to the vector case, then to the matrix case, and last tensors (i.e., the case of DNNs).&lt;&#x2F;p&gt;
&lt;p&gt;Finally, a real example is given where it is shown the backpropagation algorithm applied to a linear layer. A really nice passage is how we can avoid to compute the full (generalized) Jacobian matrix. Such matrix even for a small network can be huge and computationally expensive to compute.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;backpropagation-for-a-linear-layer&quot;&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;cs231n.stanford.edu&#x2F;handouts&#x2F;linear-backprop.pdf&quot;&gt;Backpropagation for a Linear Layer&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;em&gt;by Justin Johnson, Stanford University.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Same author, same topic, but this time the focus is on the backpropagation algorithm applied to a little bit more complex linear layer.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;backward-pass-for-a-convolutional-layer&quot;&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;sites.cc.gatech.edu&#x2F;classes&#x2F;AY2021&#x2F;cs7643_spring&#x2F;assets&#x2F;L11_CNNs.pdf&quot;&gt;Backward Pass for a Convolutional Layer&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;&lt;em&gt;by Unknown Author, Georgia Tech.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;These are slides from a course at Georgia Tech. The focus is on the backward pass of a convolutional layer.
Honestly, I‚Äôm definetely more a LaTex notes person than a slide person, but the content is good enough.
It is basically the same content of the previous notes, but applied to a convolutional layer.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;kid-ppg&quot;&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.09559&quot;&gt;KID-PPG&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;em&gt;by Christodoulos Kechris, Jonathan Dan, Jose Miranda, David Atienza, EPFL&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A really nice paper about PPG-based Heart Rate Estimation using a Knowledge-Informed Deep Learning Model.
They achieve SotA results on the &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;archive.ics.uci.edu&#x2F;dataset&#x2F;495&#x2F;ppg+dalia&quot;&gt;PPG-DaLiA&lt;&#x2F;a&gt; dataset.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;PPG-DaLiA is a publicly available dataset for PPG-based heart rate estimation. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects while performing a wide range of activities under close to real-life conditions. The included ECG data provides heart rate ground truth. The included PPG- and 3D-accelerometer data can be used for heart rate estimation, while compensating for motion artefacts.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;During my master thesis, I worked exactly on this topic and we were the SotA on this dataset. Damn, you beat me!
Anyway, I‚Äôm really happy to see that the research is going on and that new models are proposed.&lt;&#x2F;p&gt;
&lt;p&gt;What I really enjoied about this paper is this sentence:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Although deep learning methods trained as a data-driven inference problem offer promising solutions, they often underutilize ex- isting knowledge from the medical and signal processing community.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;This is exactly what I think. We should not forget the past and the knowledge that we have.
Deep Learning is cool, but we shall not reduce to dumb monkeys (I love monkeys, I swear) that limits to throw some data to a soup of linear algebra.&lt;&#x2F;p&gt;
&lt;blockquote class=&quot;
	
	
	
	
	caution
&quot;&gt;
	&lt;p class=&quot;alert-title&quot;&gt;
		&lt;i class=&quot;icon&quot;&gt;&lt;&#x2F;i&gt;Caution&lt;&#x2F;p&gt;
	&lt;p&gt;Curios thing: I‚Äôm writing this stuff in vscode with copilot enabled. It stopped working when I said stuff above. Probably it doesn‚Äôt like monkeys.&lt;&#x2F;p&gt;

&lt;&#x2F;blockquote&gt;
&lt;h1 id=&quot;readings&quot;&gt;Readings&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;I started reading, with my girlfriend, the book &lt;em&gt;G√∂del, Escher, Bach: an Eternal Golden Braid&lt;&#x2F;em&gt; by Douglas Hofstadter. Right now I don‚Äôt have any opinions, but it is really &lt;strong&gt;huge&lt;&#x2F;strong&gt;. I hope to finish it.&lt;&#x2F;li&gt;
&lt;li&gt;I read the &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.science.org&#x2F;content&#x2F;article&#x2F;sensational-breakthrough-marks-step-toward-revealing-hidden-structure-prime-numbers&quot;&gt;‚ÄòSensational breakthrough‚Äô marks step toward revealing hidden structure of prime numbers&lt;&#x2F;a&gt; article about the recent breakthrough in the field of Riemann Hypothesis. I‚Äôm not a mathematician (at least not yet), but I‚Äôm really fascinated by this kind of stuff.&lt;&#x2F;li&gt;
&lt;li&gt;I read some other stuff from Hacker News, but I don‚Äôt remember what. I should start to take notes.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;random-ideas&quot;&gt;Random Ideas&lt;&#x2F;h1&gt;
&lt;p&gt;Few weeks ago I discovered a really interesting twitter account (I‚Äôll never say x, sorry Elon) of a crazy brazilian guy known as &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;x.com&#x2F;VictorTaelin&quot;&gt;Victor Taelin&lt;&#x2F;a&gt;.
He founded a company called HOC which wants to unlock the full potential of parallel computing by proposing a new (well, really old) paradigm known as &lt;em&gt;Interaction Calculus&lt;&#x2F;em&gt;.
You can read more in this really nice &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;gist.github.com&#x2F;VictorTaelin&#x2F;77fd5a2a8a4a07e1da6157ebca3c7cf1&quot;&gt;gist&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;This guy is an expert about functional languages, type theory and proof checkers. I started reading something thanks to him and I‚Äôm really fascinated by this stuff.&lt;&#x2F;p&gt;
&lt;p&gt;Today (01&#x2F;08&#x2F;2024) I randomly found this &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;github.com&#x2F;sickcodes&#x2F;Docker-OSX&quot;&gt;repo&lt;&#x2F;a&gt; about running macOS in a docker container using QEMU. And I‚Äôm wondering what if we can emulate platforms using QEMU on GPUs with &lt;strong&gt;Interaction Calculus&lt;&#x2F;strong&gt;? Honestly this idea is not mine and comes from a comment in a blog in the HOC discord server. It such a cool idea!
Btw, &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;drewdevault.com&#x2F;2018&#x2F;09&#x2F;10&#x2F;Getting-started-with-qemu.html&quot;&gt;Getting started with qemu&lt;&#x2F;a&gt;. Read in case of fire.&lt;&#x2F;p&gt;
&lt;p&gt;Speaking of nice &lt;em&gt;functional&lt;&#x2F;em&gt; bros on twitter (not X, sorry Elon) there is also this guy &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;x.com&#x2F;ChShersh&quot;&gt;Dmitrii Kovanikov&lt;&#x2F;a&gt;. He is an OCAML chad and he just started a blog post series about Category Theory for SWEs. I‚Äôm really excited to read it.
This is the first post -&amp;gt; &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;dev.to&#x2F;chshersh&#x2F;pragmatic-category-theory-part-1-semigroup-intro-1ign&quot;&gt;Pragmatic Category Theory | Part 1: Semigroup Intro&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
